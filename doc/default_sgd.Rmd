---
title: "Project4_Group1_Spring2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

In this project, we are going to ultilize matrix factorization methods for recommender system, aiming to match consumers with most appropriate products. Matrix factorization methods represent both items and users with vectors of factors inferred from item rating patterns. High correspondence between item and user factors leads to a recommendation. 

Our group has been assigned with the following algorithm, regularization and postprocessing:

- factorization algorithm: Stochastic Gradient Descent

- regularization: Penalty of Magnitudes + Bias and Interecepts vs Penalty of Magnitudes + Temporal Dynamics

- postpocessing: KNN

We are going to compare the regularization methods and evaluate their results.

```{r include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
```


### Step 1 Load Data and Train-test Split
```{r}
data <- read.csv("../data/ml-latest-small/ratings.csv")

# did transformation on data for getting information in temporal dynamic
mean_time <- data%>%group_by(userId)%>%summarize(mean_time = mean(timestamp))
newdata <- left_join(data, mean_time, by="userId")
data <- newdata%>%mutate(sign = sign(timestamp-mean_time),diff_time = (abs(timestamp-mean_time)))

set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
```

###Step 2 Matrix Factorization

#### Step 2.1 Algorithm and Regularization
We perform stochastic gradien descent to do matrix factorization.

```{r}
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
```


#### Step 2.2 Parameter Tuning
Here we use cross validation to tune parameters: f as the dimension of factor and the penalty parameter $\lambda$ and select the best combination with the lowest test RMSE.

####Step 2.2.1 Parameter Tuning with only A1:Stochastic Gradient Descent 

```{r}
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
```


```{r, eval=FALSE}
# result_summary <- array(NA, dim = c(nrow(f_l), 10, 4)) 
# run_time <- system.time(for(i in 1:nrow(f_l)){
#     par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
#     cat(par, "\n")
#     current_result <- cv.function(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
#     result_summary[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T) 
#     print(result_summary)
#   
# })
# 
# save(result_summary, file = "../output/rmse.Rdata")
```


Plot the tuned parameters for A1: Stochastic Gradient Descent

```{r}
load("../output/rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
```

From the graphs, we can observe that the f = 10. lambda = 0.1 maintain the best performance matrics with lowest test RMSE.


#### WX's part
#### Step 2.2.2 Parameter Tuning with R1 + R2

```{r}
source("../lib/cross_validation_r1+r2.R")
source("../lib/Matrix_Factorization_r1+r2.R")
source("../lib/Matrix_Factorization_r1r3.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)

# result_summary_r12 <- array(NA, dim = c(nrow(f_l), 10, 4)) 
# run_time <- system.time(for(i in 1:nrow(f_l)){
#     par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
#     cat(par, "\n")
#     current_result <- cv.function.r12(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
#     result_summary_r12[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T) 
#     print(result_summary_r12)
#   
# })
# 
# save(result_summary_r12, file = "../output/rmseR12.Rdata")
```

####Plot the tunned parameters for R1 + R2

```{r}
# load(file = "../output/rmseR12.Rdata")
# rmse <- data.frame(rbind(t(result_summary_r12[1,,]), t(result_summary_r12[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
# rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
# rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
```

From the graphs, we can observe that the f = ??. lambda = ?? maintain the best performance matrics with lowest test RMSE.

#### Step 2.1.1 Evaluation RMSE for A1 

RMSE Function
```{r}
RMSE2 <- function(rating,est_rating){
  sqrt(mean((rating$rating-est_rating)^2))
}
```


```{r, warning=FALSE}
#result <- gradesc(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 100, #stopping.deriv = 0.01,
#                   data = data, train = data_train, test = data_test)

#save(result, file = "../output/mat_fac.RData")
```


```{r}
#  load(file = "../output/rmse.Rdata")
#  load(file = "../output/mat_fac.Rdata")
#  
#  pred_rating <- t(result$q) %*% result$p
#  rmse_sgd <- RMSE2(data_test,pred_rating)
#  cat("The RMSE of A1 model is", rmse_sgd)
```


Here is the slelected parameter for A1+P2

```{r}
load(file = "../output/rmse.Rdata")
load(file = "../output/mat_fac.Rdata")
q <- result$q
p2_result_test <- pred_knn(data_train = data_train, data_test = data_test, q)
test_rmse_p2 <- p2_result_test['rmse_test']
cat("The test RMSE of A1 with P2 model is", as.numeric(test_rmse_p2))
```

#### WX's part
#### Step 2.1.2 RMSE for R1+R2

```{r}
resultR12 <- gradesc.r12(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 1, stopping.deriv = 0.01,
                    data = data, train = data_train, test = data_test)
 
 save(resultR12, file = "../output/mat_fac_r12.RData")
```


Here is the selected set of hyperparameters for 
```{r, warning=FALSE}
load(file = "../output/mat_fac_r12.RData")
pred_rating <- t(resultr12$q) %*% resultr12$p
rmse_r12 <- RMSE2(data_test,pred_rating)
cat("The RMSE of A1 with R1 R2 model is", rmse_r12)
```

#### Step 2.1.3 RMSE for A1 + R1R3 + P2

```{r}
# result_R1R3 <- gradesc.r3(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 30, stopping.deriv = 0.01,
#                    data = data, train = data_train, test = data_test)
# 
# save(result_R1R3, file = "../output/result_R1R3.RData")
```

```{r, warning=FALSE}
load(file = "../output/result_R1R3.RData")

# load results from matrix factorization
pred_rating13 <- t(result_R1R3$q) %*% result_R1R3$p
alpha <- result_R1R3$alpha

# compute all metrics needed for ratings
mu <- mean(data_train$rating)
bi <- data_train%>%group_by(movieId)%>%summarize(bi = mean(rating)-mu)%>%arrange(movieId)
bu <- data_train%>%group_by(userId)%>%summarize(bu = mean(rating)-mu)%>%arrange(userId)
dev_u_t_train <- data_train[,6]*(data_train[,7]^0.01)
dev_u_t_test <- data_test[,6]*(data_test[,7]^0.01)
bi_train <- c()
bi_test <- c()
bu_train <- c()
bu_test <- c()
data_train_pred <- c()
dev_train <-c()

for(i in 1:nrow(data_train)){
  data_train_pred[i]<-pred_rating13[which(rownames(pred_rating13)==data_train$movieId[i]),which(colnames(pred_rating13)==data_train$userId[i])]
  dev_train[i] <- alpha[which(names(alpha)==data_train$userId[i])]*dev_u_t_train[i]
  bi_train[i] <- bi$bi[which(bi$movieId==data_train$movieId[i])]
  bu_train [i] <- bu$bu[which(bu$userId==data_train$userId[i])]
}
# the function of gettting predicted ratings for training set
pred_train_new <- data_train_pred+bi_train+bu_train+mu+dev_train

data_test_pred <- c()
dev_test <-c()
for(i in 1:nrow(data_test)){
  data_test_pred[i]<-pred_rating13[which(rownames(pred_rating13)==data_test$movieId[i]),which(colnames(pred_rating13)==data_test$userId[i])]
  dev_test[i] <- alpha[which(names(alpha)==data_test$userId[i])]*dev_u_t_test[i]
  bi_test[i] <- ifelse(length(bi$bi[which(bi$movieId==data_test$movieId[i])])==0,0,bi$bi[which(bi$movieId==data_test$movieId[i])])
  bu_test [i] <- ifelse(length(bu$bu[which(bu$userId==data_test$userId[i])])==0,0,bu$bu[which(bu$userId==data_test$userId[i])])
}
# the function of gettting predicted ratings for test set
pred_test_new <- data_test_pred+bi_test+bu_test+mu+dev_test

rmse_r3_train <- RMSE2(data_train,pred_train_new)
rmse_r3_test <- RMSE2(data_test,pred_test_new)
cat("The test RMSE of A1 with R1 and R3  model is", rmse_r3_test,"\n")
cat("The training RMSE of A1 with R1 and R3  model is", rmse_r3_train)
```



### Step 3 Postprocessing with KNN
After matrix factorization, postporcessing will be performed to improve accuracy.

KNN Function

```{r}
vec <- function(x) {
  
  return(sqrt(sum(x^2)))
  
  }

pred_knn <- function(data_train, data_test, q)
{
  
  norm_q <- apply(q,2,vec)
  sim <- t(t((t(q) %*% q)/ norm_q) / norm_q)
  colnames(sim) <- colnames(q)
  rownames(sim) <- colnames(q)
  pred_test <- rep(0,nrow(data_test))
  
  for (i in 1:nrow(data_test)){
    user_id <- data_test$userId[i]
    movie_id <- data_test$movieId[i]
    train <- data_train[data_train$userId == user_id & data_train$movieId != movie_id,]
    movie_train <- train$movieId
    sim_vec <- sim[rownames(sim) == movie_id, colnames(sim) %in% movie_train]
    movie <- names(sim_vec)[which.max(sim_vec)]
    pred_test[i] <- train[train$movieId == movie,][3]
  }
  
  pred_test <- as.matrix(unlist(pred_test))
  rmse_test <- sqrt(mean((data_test$rating-pred_test)^2))
  return(list(pred_test = pred_test, rmse_test = rmse_test))
  
}
```

###Step 3.3.2 RMSE for A1+R1+R3+P2

###RMSE for A1+P2
```{r}
q <- result$q
p2_result_test <- pred_knn(data_train = data_train, data_test = data_test, q)
test_rmse_p2 <- p2_result_test['rmse_test']
p2_result_train <- pred_knn(data_train = data_train, data_test = data_train, q)
train_rmse_p2 <- p2_result_train['rmse_test']
cat("The RMSE of A1 with P2 model is", as.numeric(test_rmse_p2))
cat("The train RMSE of A1 with P2 model is", as.numeric(train_rmse_p2),"\n")
```


###RMSE for A1+R1+R3+P2
```{r}
q <- result_R1R3$q
p2_result_test13 <- pred_knn(data_train = data_train, data_test = data_test, q)
test_rmse_p2 <- p2_result_test13['rmse_test']
p2_result_train13 <- pred_knn(data_train = data_train, data_test = data_train, q)
train_rmse_p2 <- p2_result_train13['rmse_test']
cat("The test RMSE of A1 and R1+R3 with P2 model is", as.numeric(test_rmse_p2),"\n")
cat("The training RMSE of A1 and R1+R3 with P2 model is", as.numeric(train_rmse_p2))
```



####Linear Regression


####Linear Regression for A1+R1+R2+P2



###Linear Regression for A1+R1+R2+P2
```{r}
knn <- p2_result_test13$pred_test
t_test <- tibble(knn = p2_result_test13$pred_test,
                 bi = bi_test,
                 bu = bu_test,
                 qp = data_test_pred,
                 dev = dev_test)
t_train <- tibble(y = data_train$rating,
                  knn = p2_result_train13$pred_test,
                  bi = bi_train,
                  bu = bu_train,
                  qp = data_train_pred,
                  dev = dev_train)
lm13 <- lm(y-mu~.,data=t_train)
summary(lm13)
```

```{r}
pred_new <- predict(lm13,t_test)
true_vec <- data_test$rating-mu
error_l13 <- sqrt(mean((true_vec - pred_new)^2))
error_l13 <- cat("The test RMSE of A1 and R1+R3 with P2 linear model is", as.numeric(error_l13),"\n")

pred_new <- predict(lm13,t_train%>%select(-y))
true_vec <- t_train$y - mu
error_l13 <- sqrt(mean((true_vec - pred_new)^2))
error_l13 <- cat("The training RMSE of A1 and R1+R3 with P2 linear model is", as.numeric(error_l13))
```


###Step 4: evaluation

Here we visualize training and testing RMSE by different dimension of factors and epochs

```{r}
library(ggplot2)

load(file = "../output/mat_fac.RData")
library(ggplot2)

RMSE <- data.frame(epochs = seq(10, 100, 10), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(10, 100, 10)) + xlim(c(0, 100))

```


####Result Summary

Train RMSE for A1 + P2: 1.011
Test RMSE for A1 + P2 : 1.16406

Train RMSE for A1 + R1R2 + P2 :3.648024
Test RMSE for A1 + R1R2 + P2 : 3.660152

Train RMSE for A1 + R1R3 (combination): 0.7388929
Test RMSE for A1 + R1R3 (combination): 0.9196861 

Train RMSE for A1 + R1R3 +P2: 1.277137
Test RMSE for A1 + R1R3 +P2: 1.317491 

Linear regression results:

Linear regression Train RMSE for A1 + R1R2 + P2 : 
Linear regression Test RMSE for A1 + R1R2 + P2 :

Linear regression Train RMSE for A1 + R1R3 + P2 : 0.7200523
Linear regression Test RMSE for A1 + R1R3 + P2 : 0.934901

And the best parameters for all models is F = 10, lambda = 0.1 .
After comparing all the results, we find  has the best performance.


